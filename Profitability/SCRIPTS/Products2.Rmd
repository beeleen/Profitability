---
title: "Products2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

``` {r echo=TRUE}
pacman::p_load(ggplot2, dplyr, party, caret, corrplot, reshape, rpart, rattle)
products2017 <- read.csv("~/Documents/@/UBIQUM/DATAML/Week6/Profitability/Profitability/DATASETS/existingproductattributes2017.csv")

productsPredict <- read.csv("~/Documents/@/UBIQUM/DATAML/Week6/Profitability/Profitability/DATASETS/newproductattributes2017.csv")
reset.seed <- function()
{
  # ensure results are repeatable
  set.seed(1337)
}


#Remove the column with Na
products2017$BestSellersRank <- NULL
productsPredict$BestSellersRank <- NULL

#Remove RecommendationRatio
products2017$Recommendproduct <- NULL
productsPredict$Recommendproduct <- NULL

#Remove x5StarReviews
products2017$x5StarReviews <- NULL
productsPredict$x5StarReviews <- NULL


#Remove rows with outliers and duplicated values
OutlierstoRemove <- c(135:141, 198,150,123)
products2017Clean <- products2017 %>% filter(!ProductNum %in% OutlierstoRemove )

#Combining the Sstars Reviews
products2017Clean$GoodReviews <- products2017Clean$x4StarReviews + products2017Clean$x3StarReviews
products2017Clean$BadReviews <- products2017Clean$x2StarReviews + products2017Clean$x1StarReviews

productsPredict$GoodReviews <- productsPredict$x4StarReviews + productsPredict$x3StarReviews
productsPredict$BadReviews <- productsPredict$x2StarReviews + productsPredict$x1StarReviews



####Models

#Splitting the data

intrain <- createDataPartition(y = products2017Clean$Volume, p= 0.7, list = FALSE)
train <- products2017Clean[intrain, ]
test <-  products2017Clean[-intrain, ]

reset.seed()
ctrl <- trainControl(method ="repeatedcv", repeats = 3, classProbs = TRUE, summaryFunction = multiClassSummary) 


#Base test with Decision Tree
reset.seed()
rtree_model <- rpart(Volume~x4StarReviews + PositiveServiceReview, data=train, control=rpart.control(maxdepth=10))
rtree_model
fancyRpartPlot(rtree_model) 

rtree_model2 <- rpart(Volume~., data=train, control=rpart.control(maxdepth=10))
rtree_model2
fancyRpartPlot(rtree_model2) 
varImp(rtree_model2)




#3 variables
#Random Forest
rfGrid <- expand.grid(mtry=c(1,2, 3))
plsFit <- train(Volume~GoodReviews + BadReviews + PositiveServiceReview, data = train, method = "rf",tuneGrid=rfGrid, tuneLength = 2, preProc = c("center", "scale")) 
plsFit

#Knn
rfGridKnn <- expand.grid(mtry=c(1,2, 3))
plsFitKnn <- train(Volume~GoodReviews + BadReviews + PositiveServiceReview, data = train, method = "knn", preProc = c("center", "scale")) 
plsFitKnn

#Lm
plsFitLm <- train(Volume~GoodReviews + BadReviews + PositiveServiceReview, data = train, method = "lm", tuneLength = 2, preProc = c("center", "scale")) 
plsFitLm

#3 Variables
#Random Forest
rfGrid <- expand.grid(mtry=c(1,2, 3))
plsFit2 <- train(Volume~x4StarReviews + x2StarReviews + PositiveServiceReview, data = train, method = "rf",tuneGrid=rfGrid, tuneLength = 2, preProc = c("center", "scale")) 
plsFit2

#Knn
#####
rfGridKnn2 <- expand.grid(mtry=c(1,2, 3))
plsFitKnn2 <- train(Volume~ x3StarReviews + PositiveServiceReview+ NegativeServiceReview,  data = train, method = "knn", preProc = c("center", "scale")) 
plsFitKnn2


#2 Variables
#Random Forest   ##The best results
rfGrid3 <- expand.grid(mtry=c(1,2))
plsFit3 <- train(Volume~x4StarReviews + PositiveServiceReview, data = train, method = "rf",tuneGrid=rfGrid3, tuneLength = 2, preProc = c("center", "scale")) 
plsFit3

#Knn
plsFitKnn2 <- train(Volume~x4StarReviews + PositiveServiceReview, data = train, method = "knn", preProc = c("center", "scale")) 
plsFitKnn2

#2 Variables
#Random Forest
plsFit4 <- train(Volume~GoodReviews + PositiveServiceReview, data = train, method = "rf",tuneGrid=rfGrid3, tuneLength = 2, preProc = c("center", "scale")) 
plsFit4


#Predictions for the train test with Rand. Forest
predrf <- predict(plsFit3, newdata = test)
pred_metric_rf <- postResample(test$Volume, predrf)
pred_metric_rf

#Plot the error for the test set


testPlot <- test
testPlot$predicted <- predrf
testPlot$error <- (testPlot$predicted - testPlot$Volume)/(length(testPlot))

ggplot(testPlot, aes(Volume,error)) + geom_point(aes(colour = factor(ProductType))) +geom_text(aes(label= ProductNum),hjust=0, vjust=0)

#
errorsByType <- testPlot %>% group_by(ProductType ) %>% summarise(mean(error))
errorsByType

#Predictions for the New Dataset 
predrfApply <- predict(plsFit3, newdata = productsPredict)

plot(predrfApply )

productsPredict$PredictedVolume <- predrfApply
ggplot(productsPredict, aes(x=ProductNum, y=PredictedVolume, label= ProductType)) + geom_point() +geom_text(aes(label= ProductType),hjust=0, vjust=0)

#output <- productsPredict
#write.csv(productsPredict, file="C2.T3output.csv", row.names = TRUE)




```